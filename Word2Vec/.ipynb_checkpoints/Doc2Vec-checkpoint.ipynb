{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "\n",
    "Playing around with Doc2Vec, from the paper [Distributed Representations of Sentences and Documents](https://arxiv.org/pdf/1405.4053.pdf).\n",
    "\n",
    "## Intro to Word2Vec\n",
    "**Word2Vec** creates embeddings of words using a NN with one hidden layer, which creates the embeddings for the words in the dataset.\n",
    "* **CBOW, or Continuous Bag of Words**\n",
    "    * Use context words to predict a target word  \n",
    "    * Better on smaller datasets  \n",
    "* **Skip-gram models**\n",
    "    * Use a word to predict context words  \n",
    "    * Feed model the one-hot embedding; corresponding embedding = one-hot vector * hidden layer weights\n",
    "    * Better on larger datasets, rare examples\n",
    "* **Objective:** maximize the [avg. log likelihood](https://datascience.stackexchange.com/questions/28259/connection-between-cross-entropy-and-likelihood-for-multi-class-soft-label-class)\n",
    "* [Hierarchical softmax](https://paperswithcode.com/method/hierarchical-softmax) used for prediction layer\n",
    "\n",
    "## Paragraph Vector Framework\n",
    "* Addition of a paragraph ID vector to Word2Vec Model  \n",
    "* Paragraph token can be thought of as another word  \n",
    "* Paragraph vector is then used as the feature for the paragraph  \n",
    "* Doc2Vec can be used in this way to learn both paragraph and word embeddings\n",
    "\n",
    "## Doc2Vec Architecture\n",
    "* Each word vector is a 1-hot encoding of dimension 1xV, where V is the number of words in the corpus  \n",
    "* Each paragraph vector is a 1-hot encoding of dimension 1xC, where C is the number of paragraphs  \n",
    "* Weight matrices W(VxN) and D(CxN) contain the embeddings\n",
    "![doc2vec architecture](https://shuzhanfan.github.io/assets/images/doc2vec.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\claudia.nguyen\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\claudia.nguyen\\anaconda3\\lib\\site-packages (from nltk) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\claudia.nguyen\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df=pd.read_csv('tile_descs.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id_dict = dict(zip(tile_df['Tile Name'], tile_df['Tile ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df['Text']=tile_df['Text'] + ' ' +tile_df['Theme'] + ' ' +tile_df['Story'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df['Text']=tile_df['Text'].replace('\\x1a','').replace('\\x93','').replace('\\x94','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df[tile_df['Tile Name']=='myb_mob_order_pendingplanchange'].Text[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "# tile_df['Text']=tile_df['Text'].apply(lambda x: [w for w in x if w is not None and w != ''])\n",
    "tile_df['Text']=tile_df['Text'].apply(lambda x: preprocess_string(x))\n",
    "# lemmatize\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# tile_df['Text']=tile_df['Text'].apply(lambda x: [lemmatizer.lemmatize(w) for w in x])\n",
    "# remove blanks\n",
    "tile_df['Text']=tile_df['Text'].apply(lambda x: [w for w in x if w is not None and w != '' and w !='\\x1a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dict = dict(zip(tile_df['Tile Name'], tile_df.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tile ID', 'Tile Name', 'Text', 'Theme', 'Story'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[TaggedDocument(val,[key]) for key, val in tile_dict.items()]\n",
    "documents_dict = dict(zip(tile_dict.keys(),documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tile_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size = 10, epochs=100, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate similar tiles \n",
    "for doc_id in documents_dict.keys():\n",
    "    inferred_vector = model.infer_vector(documents_dict[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    print('tile: ' + doc_id)\n",
    "    print('   words: ' + str(documents_dict[doc_id].words))\n",
    "    print('most similar:' + str(sims[0]) + '\\n   words:' + str(documents_dict[sims[0][0]].words))\n",
    "    print('2nd most similar:' + str(sims[1])+ '\\n   words:' + str(documents_dict[sims[1][0]].words))\n",
    "    print('least similar:'+ str(sims[len(model.dv)-1]) + '\\n   words:' + str(documents_dict[sims[len(model.dv)-1][0]].words))\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_ids= []\n",
    "# vectors= []\n",
    "\n",
    "# for name, tile_id in tile_id_dict.items():\n",
    "#     tile_ids.append(tile_id)\n",
    "#     vectors.append(model.dv[name])\n",
    "    \n",
    "# tile_id_to_vector_dict = dict(zip(tile_ids, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(tile_id_to_vector_dict, open('tile_embeddings.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
